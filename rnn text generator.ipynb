{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length 610871\n",
      "total chars:  59\n"
     ]
    }
   ],
   "source": [
    "with open('content\\sherlock-holmes.txt', 'r') as file:\n",
    "    text = file.read().lower()\n",
    "print('text length', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars: ', len(chars))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length is 610619\n",
      "length is 52\n",
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "bad_chars = [';','½','£', 'à', 'â', 'è', 'é']\n",
    "for i in range(len(bad_chars)):\n",
    "  text = text.replace(bad_chars[i],\"\")\n",
    "chars = sorted(list(set(text)))\n",
    "textlen = len(text)\n",
    "charlen = len(chars)\n",
    "print(\"length is \" + str(textlen))\n",
    "print(\"length is \" + str(charlen))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model building\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# optimizer = RMSprop(learning_rate=0.01)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# def on_epoch_end(epoch, logs):\n",
    "#     print()\n",
    "#     print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "#     start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "#     for diversity in [0.2, 0.5, 1.0]:\n",
    "#         print('----- diversity:', diversity)\n",
    "\n",
    "#         generated = ''\n",
    "#         sentence = text[start_index: start_index + maxlen]\n",
    "#         generated += sentence\n",
    "#         print('----- Generating with seed: \"' + sentence + '\"')\n",
    "#         sys.stdout.write(generated)\n",
    "\n",
    "#         for i in range(400):\n",
    "#             x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "#             for t, char in enumerate(sentence):\n",
    "#                 x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "#             preds = model.predict(x_pred, verbose=0)[0]\n",
    "#             next_index = sample(preds, diversity)\n",
    "#             next_char = indices_char[next_index]\n",
    "\n",
    "#             generated += next_char\n",
    "#             sentence = sentence[1:] + next_char\n",
    "\n",
    "#             sys.stdout.write(next_char)\n",
    "#             sys.stdout.flush()\n",
    "#         print()\n",
    "# print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = \"weights3.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
    "                             verbose=1, save_best_only=True,\n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1591/1591 [==============================] - ETA: 0s - loss: 2.2259\n",
      "Epoch 1: loss improved from inf to 2.22594, saving model to weights3.hdf5\n",
      "1591/1591 [==============================] - 196s 122ms/step - loss: 2.2259 - lr: 0.0010\n",
      "Epoch 2/4\n",
      "1590/1591 [============================>.] - ETA: 0s - loss: 1.8070\n",
      "Epoch 2: loss improved from 2.22594 to 1.80697, saving model to weights3.hdf5\n",
      "1591/1591 [==============================] - 205s 129ms/step - loss: 1.8070 - lr: 0.0010\n",
      "Epoch 3/4\n",
      "1591/1591 [==============================] - ETA: 0s - loss: 1.6499\n",
      "Epoch 3: loss improved from 1.80697 to 1.64987, saving model to weights3.hdf5\n",
      "1591/1591 [==============================] - 229s 144ms/step - loss: 1.6499 - lr: 0.0010\n",
      "Epoch 4/4\n",
      "1590/1591 [============================>.] - ETA: 0s - loss: 1.5473\n",
      "Epoch 4: loss improved from 1.64987 to 1.54733, saving model to weights3.hdf5\n",
      "1591/1591 [==============================] - 223s 140ms/step - loss: 1.5473 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5ba27ae80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=128, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, diversity):\n",
    "    # Get random starting text\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'weights3.hdf5'\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer ='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his arm. \"there are a few of us who frequed to he was a took of the strook of the street of the street of the seet of a compan to the prase come be an the dears was should the seet that i have to the cort and of the seature was stard to the seet of the street of his fact. there is no have all the good to an one the seed of the street of all the bellor stard up and the port of the\n",
      "     ous a glown the sent of the sitter of the little street of him for the\n",
      "     seed the strook and the the string of his gaid of his come to the she to the\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(500, 0.3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
