{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "crblMJJ4AyEp"
      },
      "outputs": [],
      "source": [
        "# Import the req lib\n",
        "import pandas as pd\n",
        "import re\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# from nltk.corpus import stopwords\n",
        "# from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2JfdpLOEBDSZ"
      },
      "outputs": [],
      "source": [
        "path = \"./content/sherlock-holmes.txt\"\n",
        "with open(path, \"r\") as file1:\n",
        "    raw_text = file1.read()\n",
        "    # print(raw_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK9Dm7VEEnK8",
        "outputId": "2624cd9d-4fd1-4766-e25a-50029ca86be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n', ' ', \"'\", '-', '1', '2', '3', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
          ]
        }
      ],
      "source": [
        "#Data Cleaning\n",
        "raw_text = raw_text.lower()[:1000]\n",
        "chars = sorted(list(set(raw_text)))\n",
        "print(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ROKWbvuFkU1",
        "outputId": "17c8b094-6b69-4f9b-b3f2-3f89211be729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n', ' ', \"'\", '-', '1', '2', '3', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
          ]
        }
      ],
      "source": [
        "# reg = re.sub('[^a-zA-Z]',' ',demo)\n",
        "bad_chars = [':',';','Â½']\n",
        "for i in range(len(bad_chars)):\n",
        "  text = raw_text.replace(bad_chars[i],\"\")\n",
        "chars = sorted(list(set(text)))\n",
        "print(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyQtOCgwHsS6",
        "outputId": "a0e31e73-dc6d-48de-fa13-20fa67d261bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length is 1000\n",
            "length is 29\n"
          ]
        }
      ],
      "source": [
        "textlen = len(text)\n",
        "charlen = len(chars)\n",
        "\n",
        "\n",
        "print(\"length is \" + str(textlen))\n",
        "print(\"length is \" + str(charlen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K8N4X6qaIHlH"
      },
      "outputs": [],
      "source": [
        "SEQ = 100\n",
        "char_to_int = dict((c,i) for i,c in enumerate(chars))\n",
        "data_x = []\n",
        "data_y = []\n",
        "\n",
        "for i in range(len(text) - SEQ):\n",
        "  xtext = text[i:i+SEQ]\n",
        "  X = [char_to_int[char] for char in xtext]\n",
        "  data_x.append(X)\n",
        "  Y = text[i+SEQ]\n",
        "  data_y.append(char_to_int[Y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8OMLO9cJ0Q7",
        "outputId": "c5d2c207-96ec-46e5-f97e-c7fb5953aa62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(900, 100, 1)\n",
            "(900, 29)\n"
          ]
        }
      ],
      "source": [
        "length = len(data_x)\n",
        "data_x = np.array(data_x)\n",
        "data_x = np.reshape(data_x,(data_x.shape[0],data_x.shape[1],1))\n",
        "data_x = data_x/float(charlen)\n",
        "\n",
        "data_y = np.array(data_y)\n",
        "data_y = np_utils.to_categorical(data_y)\n",
        "print(data_x.shape)\n",
        "print(data_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P69yPlNMLJ3v"
      },
      "outputs": [],
      "source": [
        "#Model building\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, Activation\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cJstHMMLiBA"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape = (SEQ, 1), return_sequences = True))\n",
        "model.add(Dropout (0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout (0.2))\n",
        "model.add(Dense(charlen,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMsV-7t-MIEy"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIAVAa54MpI4",
        "outputId": "489569c9-5076-4852-e917-ca8d69147f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1016\n",
            "Epoch 1: loss improved from inf to 2.10156, saving model to text generation.h5\n",
            "8/8 [==============================] - 15s 2s/step - loss: 2.1016\n",
            "Epoch 2/2\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0608\n",
            "Epoch 2: loss improved from 2.10156 to 2.06084, saving model to text generation.h5\n",
            "8/8 [==============================] - 15s 2s/step - loss: 2.0608\n"
          ]
        }
      ],
      "source": [
        "#Define the check point\n",
        "filepath=\"text generation.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "history = model.fit(data_x, data_y, epochs=2, batch_size=128, callbacks = callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhiGjGMTNgPY"
      },
      "outputs": [],
      "source": [
        "#load the network weights\n",
        "filename = 'text generation.h5'\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer ='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = \"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
        "                             verbose=1, save_best_only=True,\n",
        "                             mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=1, min_lr=0.001)\n",
        "\n",
        "callbacks = [print_callback, checkpoint, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_text(length, diversity):\n",
        "    # Get random starting text\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "    return generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(generate_text(500, 0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oPgsltJN1Gd"
      },
      "outputs": [],
      "source": [
        "# new_text =\"Let us have some You perceive that the resulting has the appearance of pure water The proportion of blood cannot be more than one in a million As he spoke he threw into the vessel a few white crystals and then added some drops of \"\n",
        "# new_text = new_text.lower()\n",
        "# chars = ['\\n', ' ', \"'\", '-', '1', '2', '3', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
        "# VOCABULARY=len(chars)\n",
        "# char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "# new_text = [char_to_int[c] for c in new_text]\n",
        "# int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "# # test_text = [char_to_int[c] for c in new_text]\n",
        "# test_text = new_text"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
